# ğŸ§Š Apache Iceberg File Format Benchmark

Uma suÃ­te completa de benchmarking para avaliar performance do Apache Iceberg com diferentes formatos de arquivo e configuraÃ§Ãµes, otimizada para execuÃ§Ã£o local com Kind/Kubernetes.

## ğŸ¯ VisÃ£o Geral

Este projeto fornece uma abordagem sistemÃ¡tica para fazer benchmark do Apache Iceberg usando vÃ¡rios formatos de arquivo (Parquet, ORC, Avro) e algoritmos de compressÃ£o. Foi projetado para ajudÃ¡-lo a tomar decisÃµes baseadas em dados sobre configuraÃ§Ãµes Ã³timas para seus casos de uso especÃ­ficos.

## âœ¨ CaracterÃ­sticas

- ğŸ“ **MÃºltiplos Formatos**: Suporte para Parquet, ORC e Avro
- ğŸ—œï¸ **Algoritmos de CompressÃ£o**: GZIP, Snappy, ZSTD, ZLIB e mais
- ğŸ“Š **Testes EscalÃ¡veis**: Escalas configurÃ¡veis de micro a grandes datasets
- ğŸ­ **IntegraÃ§Ã£o TPC-DS**: Queries e geraÃ§Ã£o de dados padrÃ£o da indÃºstria
- ğŸ³ **Containerizado**: Suporte completo Docker para resultados reproduzÃ­veis
- â˜¸ï¸ **Kubernetes Ready**: Deploy em clusters Kind locais ou K8s de produÃ§Ã£o
- ğŸ“ˆ **MÃ©tricas Abrangentes**: Analytics detalhados de performance, storage e queries

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- Docker 20.10+
- Python 3.9+
- Make
- Kind (opcional, para deployment Kubernetes)

### Executar Benchmark

```bash
# Clone o repositÃ³rio
git clone https://github.com/italovinicius18/iceberg-file-format-benchmark.git
cd iceberg-file-format-benchmark

# Build da imagem Docker
make build-image

# Execute um benchmark rÃ¡pido
make run-benchmark

# Visualize os resultados
cat RELATORIO_FINAL_FORMATOS.md
```

## ğŸ—ï¸ Estrutura do Projeto

```
iceberg-file-format-benchmark/
â”œâ”€â”€ src/                          # CÃ³digo fonte Python
â”‚   â””â”€â”€ iceberg_benchmark/       # Package principal
â”‚       â”œâ”€â”€ cli.py              # Interface de linha de comando
â”‚       â”œâ”€â”€ core.py             # LÃ³gica core do benchmark
â”‚       â””â”€â”€ utils.py            # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ configs/                     # ConfiguraÃ§Ãµes de benchmark
â”‚   â”œâ”€â”€ micro.yaml             # Micro-escala (100 rows)
â”‚   â”œâ”€â”€ small.yaml             # Pequena-escala (1K rows)
â”‚   â”œâ”€â”€ medium.yaml            # MÃ©dia-escala (10K rows)
â”‚   â””â”€â”€ large.yaml             # Grande-escala (100K rows)
â”œâ”€â”€ k8s/                        # Manifestos Kubernetes
â”œâ”€â”€ docker/                     # ConfiguraÃ§Ãµes Docker
â”œâ”€â”€ scripts/                    # Scripts de automaÃ§Ã£o
â”‚   â”œâ”€â”€ format_benchmark.py    # Benchmark original
â”‚   â””â”€â”€ corrected_format_benchmark.py  # Benchmark corrigido
â”œâ”€â”€ data/                       # Datasets gerados
â”œâ”€â”€ output/                     # Resultados de benchmark
â”œâ”€â”€ metrics/                    # MÃ©tricas de performance
â”œâ”€â”€ Makefile                    # Comandos de automaÃ§Ã£o
â”œâ”€â”€ RELATORIO_FINAL_FORMATOS.md # ğŸ“Š RelatÃ³rio final dos resultados
â””â”€â”€ README.md                   # Este arquivo
```

## âš™ï¸ ConfiguraÃ§Ã£o

Edite arquivos de configuraÃ§Ã£o em `configs/` para customizar benchmarks:

```yaml
# configs/custom.yaml
scale_factor: 0.1
formats:
  - parquet
  - orc
compressions:
  parquet: [snappy, gzip, zstd]
  orc: [snappy, zlib, zstd]
spark:
  executor_memory: "2g"
  driver_memory: "1g"
  master: "local[*]"
```

## ğŸ› ï¸ Uso

### Interface de Linha de Comando

```bash
# Execute configuraÃ§Ã£o especÃ­fica
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/configs:/app/configs \
  iceberg-benchmark:latest \
  python3 -m src.iceberg_benchmark.cli run --config configs/medium.yaml

# Execute apenas geraÃ§Ã£o de dados TPC-DS
python3 -m src.iceberg_benchmark.cli generate-data --scale 0.1 --output ./data

# Execute apenas queries
python3 -m src.iceberg_benchmark.cli run-queries --data ./data --output ./results
```

### Benchmark Corrigido de Formatos

```bash
# Execute o benchmark completo corrigido (recomendado)
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/metrics:/app/metrics \
  -v $(pwd)/scripts:/app/scripts \
  iceberg-benchmark:latest \
  python3 /app/scripts/corrected_format_benchmark.py
```

### Uso ProgramÃ¡tico

```python
from src.iceberg_benchmark.core import IcebergBenchmark
from src.iceberg_benchmark.utils import load_config

# Carregue configuraÃ§Ã£o
config = load_config('configs/medium.yaml')

# Inicialize benchmark
benchmark = IcebergBenchmark(config)

# Execute benchmark
results = benchmark.run()

# Analise resultados
benchmark.analyze_results(results)
```

## ğŸ“Š Resultados do Benchmark

### ğŸ† Principais Descobertas

Com base em **24 testes executados** em **4 escalas diferentes**, nossos resultados mostram:

#### **VENCEDOR GERAL: ORC + ZLIB**
- **ğŸ’¾ Melhor CompressÃ£o**: 8-12% menor que Parquet
- **âš¡ Melhor Performance**: 23% mais rÃ¡pido que Parquet
- **ğŸ¯ ConsistÃªncia**: Superior em todas as escalas testadas

#### **Rankings por Escala**:

| Escala | Melhor CompressÃ£o | Melhor Performance | RecomendaÃ§Ã£o |
|---------|------------------|-------------------|--------------|
| **Micro (100 rows)** | ORC + ZLIB (8.73 KB) | ORC + ZLIB (0.046s) | ORC + ZLIB |
| **Small (1K rows)** | ORC + ZSTD (61.28 KB) | ORC + ZLIB (0.042s) | ORC + ZLIB |
| **Medium (10K rows)** | ORC + ZSTD (588.87 KB) | ORC + ZLIB (0.041s) | ORC + ZLIB |
| **Large (100K rows)** | ORC + ZSTD (5.5 MB) | Parquet + GZIP (0.044s) | ORC + ZLIB |

### ğŸ“ˆ MÃ©tricas Geradas

O benchmark gera mÃ©tricas abrangentes incluindo:

- **EficiÃªncia de Storage**: Tamanhos de arquivo e taxas de compressÃ£o
- **Performance de Query**: Tempos de execuÃ§Ã£o e throughput
- **MÃ©tricas I/O**: Velocidades de leitura/escrita e padrÃµes
- **Uso de Recursos**: UtilizaÃ§Ã£o de CPU, memÃ³ria e disco

Resultados sÃ£o salvos em mÃºltiplos formatos:
- JSON para anÃ¡lise programÃ¡tica (`metrics/format_comparison_corrected.json`)
- Markdown para relatÃ³rios (`RELATORIO_FINAL_FORMATOS.md`)
- CSV para anÃ¡lise em planilhas

## ğŸš€ Deployment

### Desenvolvimento Local

```bash
# Instale dependÃªncias
pip install -r requirements.txt

# Execute testes
python -m pytest tests/

# Execute benchmark localmente
python -m src.iceberg_benchmark.cli run --config configs/micro.yaml
```

### Docker

```bash
# Build da imagem
make build-image

# Execute container
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/output:/app/output \
  iceberg-benchmark:latest
```

### Kubernetes

```bash
# Deploy em cluster Kind
make deploy-kind

# Deploy em cluster existente
kubectl apply -f k8s/

# Monitore jobs
kubectl get jobs -w
```

## ğŸ“‹ Comandos Make DisponÃ­veis

```bash
make help              # Mostra todos os comandos disponÃ­veis
make build-image        # Build da imagem Docker
make run-benchmark      # Execute benchmark completo
make clean             # Limpe dados e resultados
make deploy-kind       # Deploy no Kind
make view-results      # Visualize resultados
make test              # Execute testes
```

## ğŸ”§ ResoluÃ§Ã£o de Problemas

### Problemas Comuns

1. **Avro nÃ£o funciona**: 
   - Spark requer package `spark-avro` externo
   - SoluÃ§Ã£o: Use Parquet ou ORC (formatos nativos)

2. **Scale factor nÃ£o escala dados**:
   - Problema na implementaÃ§Ã£o original do TPC-DS
   - SoluÃ§Ã£o: Use `corrected_format_benchmark.py`

3. **Erro de memÃ³ria**:
   - Aumente configuraÃ§Ãµes Spark no YAML
   - Reduza escala dos dados

### Logs e Debugging

```bash
# Visualize logs do container
docker logs <container_id>

# Execute em modo debug
docker run --rm -it iceberg-benchmark:latest bash

# Verifique dados gerados
ls -la data/
```

## ğŸ§ª Testes

```bash
# Execute todos os testes
python -m pytest tests/ -v

# Execute testes especÃ­ficos
python -m pytest tests/test_core.py -v

# Execute com cobertura
python -m pytest tests/ --cov=src/iceberg_benchmark --cov-report=html
```

## ğŸ¤ Contribuindo

1. Fork o repositÃ³rio
2. Crie uma branch de feature (`git checkout -b feature/amazing-feature`)
3. FaÃ§a suas mudanÃ§as
4. Adicione testes
5. Commit suas mudanÃ§as (`git commit -m 'Add amazing feature'`)
6. Push para a branch (`git push origin feature/amazing-feature`)
7. Abra um Pull Request

### Diretrizes de ContribuiÃ§Ã£o

- Siga PEP 8 para cÃ³digo Python
- Adicione testes para novas funcionalidades
- Atualize documentaÃ§Ã£o conforme necessÃ¡rio
- Use commits semÃ¢nticos

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

- **Issues**: [GitHub Issues](https://github.com/italovinicius18/iceberg-file-format-benchmark/issues)
- **DiscussÃµes**: [GitHub Discussions](https://github.com/italovinicius18/iceberg-file-format-benchmark/discussions)
- **DocumentaÃ§Ã£o**: [Wiki](https://github.com/italovinicius18/iceberg-file-format-benchmark/wiki)

## ğŸ™ Agradecimentos

- Apache Iceberg Community
- Apache Spark Team
- TPC-DS Benchmark Committee
- Docker e Kubernetes Teams

---

## ğŸ¯ PrÃ³ximos Passos

1. **Suporte Avro**: Adicionar package spark-avro Ã  imagem Docker
2. **Mais Escalas**: Testes com datasets realmente grandes (1M+ rows)
3. **Queries Complexas**: Implementar queries TPC-DS completas
4. **Cluster Testing**: Testes em clusters multi-node
5. **Dashboard**: Interface web para visualizaÃ§Ã£o de resultados

---

*Projeto desenvolvido para benchmarking sistemÃ¡tico do Apache Iceberg com foco em decisÃµes baseadas em dados para otimizaÃ§Ã£o de performance e storage.*
